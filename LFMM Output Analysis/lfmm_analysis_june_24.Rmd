---
title: "LFMM analysis"
author: "Isabel Bojanini"
date: "2025-06-24"
output: html_document
---

```{r}
library(LEA)
library(dplyr)
library(ggplot2)
```

## R Markdown
Load all data
```{r cars}

#RDS
temp_pcs=readRDS("/scratch/ib2382/GEA/June_lfmm_804/K6/june_27_output2.rds")
prec_pcs=readRDS("/scratch/ib2382/GEA/June_lfmm_804/K6/june_27_output1.rds")
temp6=readRDS("/scratch/ib2382/GEA/June_lfmm_804/K6/july_3rd2.rds") #PET

```

Quality control figures:


```{r pressure, echo=FALSE}

# Open a PNG file for the multi-panel plot
png("/scratch/ib2382/GEA/June_lfmm_804/K6/qc_histogram_qqplot.png", width = 700, height = 1500)

# Set up a 2x2 plotting area
par(mfrow = c(8, 2))

project_list=c("prec_pcs", "temp_pcs","moisture_pcs","temp6")
for (proj_name in project_list) {
  project_data <- get(proj_name)
  hist(project_data$pvalues, main = paste("Unadjusted p-values:", proj_name))
  qqplot(rexp(length(project_data$pvalues),rate=log(10)),
         -log10(project_data$pvalues),xlab=paste("Expected quantile",proj_name))
  abline(0,1)
}

# Turn off plotting device
dev.off()
```

This code chunk generates 2 data frames: FDR adjusted p.values (so these are q.values) and z.scores
```{r}

project_list=c("prec_pcs_10_KB", "temp_pcs_10_KB","temp6_10_KB")
q.values_list=c()
for (project in project_list){
  project_data <- get(project)
  #print(project_data)
  q.values_list[[project]]=p.adjust(project_data$pvalues, method="fdr")
}
q.values=as.data.frame(q.values_list)

z.scores_list=c()
for (project in project_list){
  project_data <- get(project)
  #print(project_data)
  z.scores_list[[project]]=project_data$zscores
}
z.scores=as.data.frame(z.scores_list)
```

Making a chromosome table where the Z scores and q.values will be stored:
```{r}
#snp_maf_table = read.table("/scratch/ib2382/plink_indica_mac_geno_imp_804_005.bim", header=FALSE)
snp_maf_table = read.table("/scratch/ib2382/GEA/June_lfmm_804/K6_10kb_pruning/plink_indica_mac_geno_imp_804_005_10kb.bim", header=FALSE)
library(dplyr)
snp_maf_table = snp_maf_table %>% dplyr::select(V1,V4)

nrow(snp_maf_table)

snp_maf_table$SNP= paste0("Os", 1:nrow(snp_maf_table))

colnames(snp_maf_table)=c("CHROM", "POS","SNP")

snp_maf_table$CHROM_NUM <- snp_maf_table$CHROM  # copy column

CHROM_NAME <- unique(snp_maf_table$CHROM)

for (i in seq_along(CHROM_NAME)) {
  snp_maf_table$CHROM_NUM[snp_maf_table$CHROM == CHROM_NAME[i]] <- i
}

q.value.snp=cbind(snp_maf_table,q.values)

q.value.snp$CHROM_NUM=as.numeric(q.value.snp$CHROM_NUM)

q.value.snp$POS=as.numeric(q.value.snp$POS)

z.value.snp=cbind(snp_maf_table,z.scores)

write.csv(q.value.snp,"/scratch/ib2382/GEA/June_lfmm_804/K6_10kb_pruning/qvalueslfmm.csv")
write.csv(z.value.snp,"/scratch/ib2382/GEA/June_lfmm_804/K6_10kb_pruning/zscoreslfmm.csv")

```

Getting the significant values:
```{r}
temp0.05=q.value.snp[which(q.value.snp$temp_pcs< 0.05), ]
prec0.05=q.value.snp[which(q.value.snp$prec_pcs< 0.05), ]
temp60.05=q.value.snp[which(q.value.snp$temp6< 0.05), ]


temp0.01=q.value.snp[which(q.value.snp$temp_pcs< 0.01), ]
prec0.01=q.value.snp[which(q.value.snp$prec_pcs< 0.01), ]
temp60.01=q.value.snp[which(q.value.snp$temp6< 0.01), ]

```

Code to generate manhattan plots
```{r}
#install.packages("remotes")
#remotes::install_github("leejs-abv/ggmanh")
library(ggmanh)
library(dplyr)
library(qqman)

# Define alternating chromosome colors
chr_colors <- c("black", "azure4")

# Convert CHROM to factor
q.value.snp$CHROM_NUM <- factor(q.value.snp$CHROM_NUM, c(1:12))

# Assign alternating colors and highlight significant SNPs
snp_table <- q.value.snp %>%
  mutate(chr_color = ifelse(as.numeric(CHROM_NUM) %% 2 == 0,"black", "azure4"),
         plot_color =  chr_color)
         plot_color = ifelse(temp6 <= 0.05, "brown2", chr_color))  # Adjust significance as needed

# Define color mapping
highlight_colormap <- c("black" = "black", 
                        "azure4" = "azure4", 
                        "brown2" = "brown2")



# Preprocess data for Manhattan plot
tmp <- manhattan_data_preprocess(
  test, pval.colname = "temp_pcs_10_KB", 
  chr.colname = "CHROM_NUM", 
  pos.colname = "POS",
  highlight.colname = "plot_color", 
  highlight.col = highlight_colormap,
  signif = c(0.01,0.05)
)

  
# Generate Manhattan plot with custom threshold line
g <- manhattan_plot(
  tmp, plot.title = "Temperature PC1 Manhattan plot",
  color.by.highlight = TRUE,
  signif = c(0.01,0.05))

q <- g +
  geom_hline(yintercept = -log10(0.01), color = "red", linetype = "dashed", linewidth = 0.5) +
  geom_hline(yintercept = -log10(0.05), color = "blue", linetype = "dashed", linewidth = 0.5)+
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))

#Save the plots
png("/scratch/ib2382/GEA/June_lfmm_804/K6_10kb_pruning/", width = 1200, height = 800, res = 150)

# Print the updated plot into the PNG device
print(q)

# Close the PNG device to write the file
dev.off()
```


#Getting peaks
the dataframe "boundaries" should give a table with the most significant snp, and its position. As well as the peak size, start and end position. 
Note: Ornob created this script. I just tweaked a few lines.
```{r}

library(dplyr) #to subset and mutate columns as we go

# These are your q.value columns (environmental variables)
qval_columns = c(colnames(q.value.snp))  #or replace with your actual q.value column names
qval_columns = c("prec_pcs_10_KB", "temp_pcs_10_KB","temp6_10_KB")
# Create a list to store results
clumped_results <- list()

# Loop through each q.value column. You set this up in a previous line
for (var in qval_columns) {
  
  # Filter SNPs where q.value < 0.01
  filtered <- q.value.snp %>%
    filter(.data[[var]] < 0.01) %>%
    arrange(CHROM_NUM, POS)  # Make sure it's sorted, we will use this to create "chains"
  
  if (nrow(filtered) > 0) {
    # Initialize chain vector
    chain <- rep(1, nrow(filtered))
    
    # Loop to assign chain groups
    for (i in 2:nrow(filtered)) {
      if (filtered$CHROM_NUM[i] != filtered$CHROM_NUM[i - 1] ||
          filtered$POS[i] - filtered$POS[i - 1] > 100000) {
        chain[i] = chain[i - 1] + 1
      } else {
        chain[i] = chain[i - 1]
      }
    }
    
    # Add the chain column
    filtered$chain = chain
  } else {
    filtered$chain = integer(0)
  }
  
  # Save the result
  clumped_results[[var]] = filtered
}
for (var in names(clumped_results)) {
  write.csv(clumped_results[[var]], paste0("clumped_", var, ".csv"), row.names = FALSE)
}

```

Finding peak based on the previously found "clumps"
```{r}

get_boundaries_LD <- function(df, column) {
  boundaries2 <- df %>%
    group_by(chain) %>%
    summarise(
      CHROM = first(CHROM_NUM), # keep chromosome
      sig_SNP = min(.data[[column]]), # min q.value
      sig_SNP_POS = POS[which.min(.data[[column]])],
      sig_SNP_name = SNP[which.min(.data[[column]])],
      peak_start = sig_SNP_POS - 100000,
      peak_end = sig_SNP_POS + 100000,
      snps_in_chain = n(), #this is to count the # of SNPs within the chain or clump
      .groups = "drop"
    ) %>%
    arrange(CHROM, sig_SNP_POS) %>%# order chains
    group_by(CHROM) %>% # reset lag within chromosome
    mutate(dist.focal.snp = sig_SNP_POS - lag(sig_SNP_POS)) %>% #to get the distances between focal SNPs
    ungroup()
  
  return(boundaries2)
}

boundaries_temp=get_boundaries_LD(clumped_results$temp_pcs_10_KB, "temp_pcs_10_KB")
boundaries_prec=get_boundaries_LD(clumped_results$prec_pcs_10_KB, "prec_pcs_10_KB")
boundaries_temp6=get_boundaries_LD(clumped_results$temp6_10_KB, "temp6_10_KB")

write.csv(boundaries_temp, "boundaries_temp.csv", row.names = F)
write.csv(boundaries_prec, "boundaries_prec.csv",row.names = F)
write.csv(boundaries_temp6, "boundaries_temp6.csv",row.names = F)

```

#Check for peaks that could be near too near others
```{r}
peak_distance_test=boundaries_temp %>% 
  group_by(CHROM) %>% 
  mutate(distance_between=peak_start-lag(peak_end))
peak_distance_test$distance_between<"100000"
```

To annotate the peaks:

This next part is to merge your data with GFF files:
```{r}
library(dplyr )
gff_os=read.table("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/R498_IGDBv3_coreset/R498_IGDBv3_coreset.gff")


gff_V1=gff_os %>% 
  mutate(V1=case_when(
    V1=="Chr1" ~ "1",
    V1=="Chr2" ~ "2",
    V1=="Chr3" ~ "3",
    V1=="Chr4" ~ "4",
    V1=="Chr5" ~ "5",
    V1=="Chr6" ~ "6",
    V1=="Chr7" ~ "7",
    V1=="Chr8" ~ "8",
    V1=="Chr9" ~ "9",
    V1=="Chr10" ~ "10",
    V1=="Chr11" ~ "11",
    V1=="Chr12" ~ "12"))


colnames(gff_V1)=c("CHROM","source","feature","start","end","score","strand","frame","descriptor")

```
 
Files to make the conversion from Shuhui to nipponbare 
```{r}
shuAnno = read.delim("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/R498_IGDBv3_coreset/R498_IGDBv3_coreset_MSU.anno",header=FALSE,col.names = c("ID","LOC","func"))

```

```{r}
not_all_na <- function(x) any(!is.na(x))

nipAnno = read.csv("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/annotation_files/RAP-MSU_2024-01-11.txt",header=FALSE,col.names =paste0("V",1:100)) %>%
  dplyr::select(where(not_all_na)) %>% 
  separate(col = V1,into = c("ID","V1"),sep = "\t") %>%
  tidyr::pivot_longer(cols = paste0("V",1:(ncol(.)-1))) %>%
  dplyr::select(ID,value) %>%
  dplyr::filter(str_count(value) > 1, value != "None") %>%
  dplyr::filter(ID != "None") %>%
  separate(col = value, into = c("LOC","remove"),remove = FALSE,sep = "\\.") %>%
  dplyr::select(!remove) %>%
  dplyr::select(ID,LOC) %>% unique()
```

```{r}
read_gff = function(filename){
  
  not_all_na <- function(x) any(!is.na(x))
  
  gff = read.delim(filename,sep = ";",header=FALSE,col.names =paste0("V",1:100) ) %>% dplyr::select(where(not_all_na)) %>%
  separate(col = V1, into = c("seqname","source","feature","start","end",
                              "score","strand","frame","V1"),sep = "\t")
  
  nv = ncol(gff) - 8
  gff = gff %>% tidyr::pivot_longer(cols = paste0("V",1:nv)) %>%
  separate(col = value, into = c("field","value"),sep = "=") %>%
    dplyr::select(-name) %>%
    dplyr::filter(!is.na(value)) %>% pivot_wider(names_from = "field")
  return(gff)
}
```

```{r}
nipLociRep = read_gff("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/annotation_files/locus.gff")
shuLoci = read_gff("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/annotation_files/R498_genes.gff")
nipCuratedRep = read.delim("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/annotation_files/IRGSP-1.0_representative_annotation_2024-01-11.tsv",sep="\t",header=TRUE)

traitOncology = read.delim("/scratch/ib2382/GEA/renameno_soil_806_lfmm_analysis/annotation_files/results.tsv") %>%
  dplyr::select(Locus.ID,Trait.Ontology..TO.)
colnames(traitOncology) = c("Locus_ID","Trait_Oncology")
nipCuratedRep = dplyr::left_join(nipCuratedRep,traitOncology)
```

Then, do left_joins with your OsR498 IDs of interest

First map to the LOC number for the gene, then using the LOC number, map to the Nipponbare annotations
```{r}

extract_os_word <- function(x) {
  # Split the string by both semicolons and "ID="
  components <- unlist(strsplit(x, ";|ID=|Parent="))  
  os_word <- components[grep("Os", components)]  # Find components that start with "Os"
  if (length(os_word) > 0) {
    return(os_word[1])  # Return the first match if there are any matches
  } else {
    return(NA)  # Return NA if no matches are found
  }
}

merge_to_annotate=function(boundaries){
  gff_temp_boundaries=merge(boundaries, gff_V1, by = "CHROM")
  merged_temp_gff_peaks<- gff_temp_boundaries %>%
    filter(start >= peak_start & end <= peak_end)
  merged_gff_peaks_os=merged_temp_gff_peaks %>%
    mutate(ID  = sapply(descriptor, extract_os_word))
  shuAnno_snps=merge(merged_gff_peaks_os,shuAnno, by="ID")
  shuhui_snps=merge(shuAnno_snps,nipAnno, by= "LOC")
  names(shuhui_snps)[ncol(shuhui_snps)] <- "Locus_ID" 
  total_boundary_genelist=merge(shuhui_snps,nipCuratedRep, by= "Locus_ID")
  return(total_boundary_genelist)
}

precipitation_annotations=merge_to_annotate(boundaries_prec)
temperature_annotations=merge_to_annotate(boundaries_temp)
evapotranspiration_annotations=merge_to_annotate(boundaries_temp6)

#write.csv(precipitation_annotations, "precipitation_annotations.csv", row.names = F)
#write.csv(temperature_annotations, "temperature_annotations.csv", row.names = F)
#write.csv(evapotranspiration_annotations, "evapotranspiration_annotations.csv", row.names = F)
```


